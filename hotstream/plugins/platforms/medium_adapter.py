"""
Medium å¹³å°é€‚é…å™¨ - åŸºäº Playwright å®ç°
"""

import asyncio
import re
from typing import Dict, List, Any, AsyncIterator, Optional
from urllib.parse import quote, urljoin
from datetime import datetime
from loguru import logger
from playwright.async_api import async_playwright, Browser, Page, Playwright

from ...core.interfaces import PlatformAdapter, DataItem, SearchOptions, RateLimitInfo


class MediumAdapter(PlatformAdapter):
    """Medium å¹³å°é€‚é…å™¨ - ä½¿ç”¨ Playwright è®¿é—® Medium"""
    
    platform_name = "medium"
    
    def __init__(self):
        self.authenticated = False
        self.playwright: Optional[Playwright] = None
        self.browser: Optional[Browser] = None
        self.page: Optional[Page] = None
        self.rate_limit = RateLimitInfo(
            requests_per_minute=30,  # Medium æœ‰è¾ƒä¸¥æ ¼çš„é™åˆ¶
            requests_per_hour=150,
            remaining=30
        )
        self.base_url = "https://medium.com"
        self.email = None
        self.password = None
    
    async def authenticate(self, credentials: Optional[Dict[str, Any]] = None) -> bool:
        """åˆå§‹åŒ– Playwright æµè§ˆå™¨å¹¶ç™»å½• Medium"""
        try:
            logger.info("åˆå§‹åŒ– Medium é€‚é…å™¨")
            
            # å¯åŠ¨ Playwright
            self.playwright = await async_playwright().start()
            
            # å¯åŠ¨æµè§ˆå™¨
            self.browser = await self.playwright.chromium.launch(
                headless=False,  # Medium æ£€æµ‹æœºå™¨äººï¼Œå»ºè®®ä½¿ç”¨æœ‰å¤´æ¨¡å¼
                args=[
                    '--no-sandbox',
                    '--disable-blink-features=AutomationControlled',
                    '--disable-web-security',
                    '--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
                ]
            )
            
            # åˆ›å»ºé¡µé¢
            self.page = await self.browser.new_page()
            
            # è®¾ç½®è§†å£
            await self.page.set_viewport_size({"width": 1366, "height": 768})
            
            # å¦‚æœæä¾›äº†è®¤è¯ä¿¡æ¯ï¼Œå°è¯•ç™»å½•
            if credentials and credentials.get('email') and credentials.get('password'):
                self.email = credentials.get('email')
                self.password = credentials.get('password')
                
                if await self._login():
                    logger.info("Medium ç™»å½•æˆåŠŸ")
                    self.authenticated = True
                    return True
                else:
                    logger.warning("Medium ç™»å½•å¤±è´¥ï¼Œå°†ä»¥åŒ¿åæ¨¡å¼è¿è¡Œ")
            
            # å³ä½¿æ²¡æœ‰ç™»å½•ï¼Œä¹Ÿæµ‹è¯•é¡µé¢è®¿é—®
            await self.page.goto(self.base_url, timeout=30000)
            await self.page.wait_for_load_state("networkidle")
            
            # æ£€æŸ¥é¡µé¢æ˜¯å¦åŠ è½½æˆåŠŸ
            title = await self.page.title()
            if "medium" in title.lower():
                logger.info("Medium é¡µé¢è®¿é—®æˆåŠŸï¼ˆåŒ¿åæ¨¡å¼ï¼‰")
                self.authenticated = True
                return True
            else:
                logger.error(f"Medium é¡µé¢å“åº”å¼‚å¸¸ï¼Œé¡µé¢æ ‡é¢˜: {title}")
                return False
            
        except Exception as e:
            logger.error(f"Medium é€‚é…å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            await self.cleanup()
            return False
    
    async def _login(self) -> bool:
        """ç™»å½• Medium"""
        try:
            logger.info("å¼€å§‹ç™»å½• Medium")
            
            # è®¿é—®ç™»å½•é¡µé¢
            await self.page.goto(f"{self.base_url}/m/signin", timeout=30000)
            await self.page.wait_for_load_state("networkidle")
            
            # æŸ¥æ‰¾å¹¶ç‚¹å‡»"Sign in with email"æŒ‰é’®
            email_button_selector = 'button:has-text("Sign in with email"), a:has-text("Sign in with email")'
            try:
                await self.page.wait_for_selector(email_button_selector, timeout=10000)
                await self.page.click(email_button_selector)
                await asyncio.sleep(2)
            except:
                logger.info("æœªæ‰¾åˆ°é‚®ç®±ç™»å½•æŒ‰é’®ï¼Œå°è¯•ç›´æ¥è¾“å…¥é‚®ç®±")
            
            # è¾“å…¥é‚®ç®±
            email_input_selectors = [
                'input[type="email"]',
                'input[name="email"]',
                'input[placeholder*="email" i]',
                'input[placeholder*="Email" i]'
            ]
            
            email_filled = False
            for selector in email_input_selectors:
                try:
                    await self.page.wait_for_selector(selector, timeout=5000)
                    await self.page.fill(selector, self.email)
                    email_filled = True
                    logger.info("é‚®ç®±è¾“å…¥æˆåŠŸ")
                    break
                except:
                    continue
            
            if not email_filled:
                logger.error("æœªæ‰¾åˆ°é‚®ç®±è¾“å…¥æ¡†")
                return False
            
            # ç‚¹å‡»ç»§ç»­æŒ‰é’®
            continue_selectors = [
                'button:has-text("Continue")',
                'button:has-text("Next")',
                'button[type="submit"]',
                'input[type="submit"]'
            ]
            
            for selector in continue_selectors:
                try:
                    await self.page.click(selector)
                    await asyncio.sleep(3)
                    break
                except:
                    continue
            
            # è¾“å…¥å¯†ç 
            password_input_selectors = [
                'input[type="password"]',
                'input[name="password"]',
                'input[placeholder*="password" i]',
                'input[placeholder*="Password" i]'
            ]
            
            password_filled = False
            for selector in password_input_selectors:
                try:
                    await self.page.wait_for_selector(selector, timeout=10000)
                    await self.page.fill(selector, self.password)
                    password_filled = True
                    logger.info("å¯†ç è¾“å…¥æˆåŠŸ")
                    break
                except:
                    continue
            
            if not password_filled:
                logger.error("æœªæ‰¾åˆ°å¯†ç è¾“å…¥æ¡†")
                return False
            
            # ç‚¹å‡»ç™»å½•æŒ‰é’®
            login_selectors = [
                'button:has-text("Sign in")',
                'button:has-text("Log in")',
                'button:has-text("Continue")',
                'button[type="submit"]',
                'input[type="submit"]'
            ]
            
            for selector in login_selectors:
                try:
                    await self.page.click(selector)
                    break
                except:
                    continue
            
            # ç­‰å¾…ç™»å½•å®Œæˆ
            await asyncio.sleep(5)
            await self.page.wait_for_load_state("networkidle")
            
            # æ£€æŸ¥æ˜¯å¦ç™»å½•æˆåŠŸ
            current_url = self.page.url
            if "signin" not in current_url and "login" not in current_url:
                logger.info("Medium ç™»å½•æˆåŠŸ")
                return True
            else:
                logger.error("Medium ç™»å½•å¤±è´¥")
                return False
                
        except Exception as e:
            logger.error(f"Medium ç™»å½•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return False
    
    async def search(self, keywords: List[str], options: SearchOptions) -> AsyncIterator[DataItem]:
        """æœç´¢ Medium æ–‡ç« """
        if not self.authenticated:
            await self.authenticate({})
        
        if not self.page or self.page.is_closed():
            logger.error("é¡µé¢ä¸å¯ç”¨")
            return
        
        try:
            total_found = 0
            for keyword in keywords:
                if total_found >= options.limit:
                    break
                
                logger.info(f"æœç´¢å…³é”®è¯: {keyword}")
                
                # æ„å»ºæœç´¢URL
                search_url = f"{self.base_url}/search?q={quote(keyword)}"
                await self.page.goto(search_url, timeout=30000)
                await self.page.wait_for_load_state("networkidle")
                await asyncio.sleep(3)
                
                # ç­‰å¾…æ–‡ç« åŠ è½½
                try:
                    await self.page.wait_for_selector('div[role="link"], article, div[data-testid="story"]', timeout=10000)
                except:
                    logger.warning(f"å…³é”®è¯ '{keyword}' æœªæ‰¾åˆ°æ–‡ç« ")
                    continue
                
                # è·å–æ–‡ç« åˆ—è¡¨
                articles = await self.page.query_selector_all('div[role="link"], article, div[data-testid="story"]')
                logger.info(f"æ‰¾åˆ° {len(articles)} ç¯‡æ–‡ç« ")
                
                for i, article in enumerate(articles):
                    if total_found >= options.limit:
                        break
                    
                    try:
                        # æå–æ–‡ç« ä¿¡æ¯
                        data_item = await self._extract_article_data(article, keyword)
                        if data_item:
                            total_found += 1
                            yield data_item
                            
                            # é¿å…è¢«åçˆ¬è™«
                            await asyncio.sleep(1)
                    
                    except Exception as e:
                        logger.warning(f"æå–æ–‡ç« æ•°æ®å¤±è´¥: {e}")
                        continue
                
                # å…³é”®è¯ä¹‹é—´çš„å»¶è¿Ÿ
                await asyncio.sleep(2)
                
        except Exception as e:
            logger.error(f"Medium æœç´¢å¤±è´¥: {e}")
    
    async def _extract_article_data(self, article_element, keyword: str) -> Optional[DataItem]:
        """ä»æ–‡ç« å…ƒç´ ä¸­æå–æ•°æ®"""
        try:
            # æå–æ ‡é¢˜
            title_selectors = [
                'h1', 'h2', 'h3',
                '[data-testid="post-preview-title"] h2',
                '[data-testid="post-preview-title"] h3',
                'a[aria-label] h2',
                'a[aria-label] h3',
                '.story-title',
                'article h2',
                'article h3'
            ]
            
            title = ""
            title_element = None
            for selector in title_selectors:
                try:
                    title_element = await article_element.query_selector(selector)
                    if title_element:
                        title = await title_element.inner_text()
                        if title.strip() and len(title) > 5:  # ç¡®ä¿æ ‡é¢˜æœ‰æ„ä¹‰
                            break
                except:
                    continue
            
            if not title:
                logger.debug("æœªæ‰¾åˆ°æ–‡ç« æ ‡é¢˜ï¼Œè·³è¿‡")
                return None
            
            # æå–ä½œè€… - æ”¹è¿›é€‰æ‹©å™¨
            author_selectors = [
                '[data-testid="post-preview-author"] a',
                'a[rel="author"]',
                'a[href*="/@"]',
                '[data-testid="post-preview-author"] span',
                '.story-author a',
                'p a[href*="/@"]',
                'div a[href*="/@"]'
            ]
            
            author = "Unknown"
            author_url = ""
            for selector in author_selectors:
                try:
                    author_element = await article_element.query_selector(selector)
                    if author_element:
                        author_text = await author_element.inner_text()
                        author_href = await author_element.get_attribute('href')
                        if author_text.strip() and len(author_text.strip()) > 1:
                            # æ¸…ç†ä½œè€…åï¼ˆç§»é™¤å¤šä½™çš„ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦ï¼‰
                            author = author_text.strip().replace('\n', ' ').replace('\t', ' ')
                            author = ' '.join(author.split())  # åˆå¹¶å¤šä¸ªç©ºæ ¼
                            if author_href and '/@' in author_href:
                                # æ¸…ç†ä½œè€…é“¾æ¥ï¼Œç§»é™¤sourceå‚æ•°å’Œå¤šä½™çš„ç ´æŠ˜å·
                                clean_href = author_href.split('?')[0]  # ç§»é™¤æŸ¥è¯¢å‚æ•°
                                author_url = clean_href if clean_href.startswith('http') else f"{self.base_url}{clean_href}"
                            break
                except:
                    continue
            
            # æå–æ–‡ç« é¢„è§ˆå†…å®¹ - æ”¹è¿›é€‰æ‹©å™¨
            content_selectors = [
                '[data-testid="post-preview-content"] p',
                '[data-testid="post-preview-content"]',
                '.story-content p',
                '.story-content',
                'article p:not(:has(a[href*="/@"]))',  # æ’é™¤ä½œè€…ä¿¡æ¯æ®µè½
                'div p',
                'p'
            ]
            
            content = ""
            for selector in content_selectors:
                try:
                    content_elements = await article_element.query_selector_all(selector)
                    content_parts = []
                    for element in content_elements[:3]:  # æœ€å¤šå–å‰3ä¸ªæ®µè½
                        text = await element.inner_text()
                        if text.strip() and len(text.strip()) > 10:
                            # è¿‡æ»¤æ‰å¯èƒ½æ˜¯ä½œè€…ä¿¡æ¯æˆ–æ—¥æœŸçš„æ–‡æœ¬
                            if not any(indicator in text.lower() for indicator in ['follow', 'member', 'written by', 'Â·', 'min read']):
                                content_parts.append(text.strip())
                    
                    if content_parts:
                        content = ' '.join(content_parts)
                        break
                except:
                    continue
            
            # æå–æ–‡ç« é“¾æ¥ - ä¼˜å…ˆä»data-hrefå±æ€§è·å–
            url = ""
            
            # é¦–å…ˆå°è¯•ä»çˆ¶å®¹å™¨çš„data-hrefå±æ€§è·å–
            try:
                data_href = await article_element.get_attribute('data-href')
                if data_href and ('/p/' in data_href or '/s/' in data_href or 'medium.com' in data_href):
                    url = data_href if data_href.startswith('http') else f"{self.base_url}{data_href}"
            except:
                pass
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•å…¶ä»–é€‰æ‹©å™¨
            if not url:
                link_selectors = [
                    'h1 a[href]', 'h2 a[href]', 'h3 a[href]',
                    '[data-testid="post-preview-title"] a[href]',
                    'a[aria-label][href]'
                ]
                
                for selector in link_selectors:
                    try:
                        link_element = await article_element.query_selector(selector)
                        if link_element:
                            href = await link_element.get_attribute('href')
                            if href:
                                # è¿‡æ»¤æ‰ä½œè€…é“¾æ¥ï¼Œåªè¦æ–‡ç« é“¾æ¥
                                if '/@' not in href or ('/p/' in href or '/s/' in href):
                                    if href.startswith('/'):
                                        url = f"{self.base_url}{href}"
                                    elif href.startswith('http'):
                                        url = href
                                    break
                    except:
                        continue
            
            # æå–å‘å¸ƒæ—¶é—´ - æ”¹è¿›é€»è¾‘å¹¶è½¬æ¢ä¸ºæ—¶é—´æˆ³
            publish_time = ""
            publish_timestamp = None
            
            # é¦–å…ˆæŸ¥æ‰¾timeæ ‡ç­¾
            try:
                time_elements = await article_element.query_selector_all('time')
                for time_elem in time_elements:
                    time_text = await time_elem.inner_text()
                    datetime_attr = await time_elem.get_attribute('datetime')
                    if time_text.strip():
                        publish_time = time_text.strip()
                        break
                    elif datetime_attr:
                        publish_time = datetime_attr
                        break
            except:
                pass
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°timeæ ‡ç­¾ï¼ŒæŸ¥æ‰¾åŒ…å«æ—¶é—´å…³é”®è¯çš„æ–‡æœ¬
            if not publish_time:
                try:
                    all_elements = await article_element.query_selector_all('span, div, p')
                    import re
                    
                    for elem in all_elements:
                        text = await elem.inner_text()
                        if text and len(text.strip()) < 50:  # é™åˆ¶é•¿åº¦
                            # åŒ¹é…æ—¶é—´æ ¼å¼ï¼šå¦‚ "5d ago", "2 hours ago", "Jan 15", ç­‰
                            time_patterns = [
                                r'\d+[dhm]\s+ago',  # 5d ago, 2h ago, 30m ago
                                r'\d+\s+(day|hour|minute|week|month|year)s?\s+ago',  # 2 days ago
                                r'(Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\s+\d+',  # Jan 15
                                r'\d{4}-\d{2}-\d{2}',  # 2023-12-25
                            ]
                            
                            for pattern in time_patterns:
                                if re.search(pattern, text, re.IGNORECASE):
                                    publish_time = text.strip()
                                    break
                            
                            if publish_time:
                                break
                except:
                    pass
            
            # è½¬æ¢å‘å¸ƒæ—¶é—´ä¸ºæ—¶é—´æˆ³
            if publish_time:
                publish_timestamp = self._convert_time_to_timestamp(publish_time)
            
            # æå–ç‚¹èµæ•° - æ”¹è¿›é€»è¾‘ï¼ŒåŸºäºè°ƒè¯•å‘ç°
            claps = ""
            try:
                # æŸ¥æ‰¾æ‰€æœ‰åŒ…å«æ•°å­—çš„spanå…ƒç´ 
                all_spans = await article_element.query_selector_all('span, div')
                import re
                
                for span in all_spans:
                    text = await span.inner_text()
                    if text and text.strip():
                        # åŒ¹é…ç‚¹èµæ•°æ ¼å¼ï¼šçº¯æ•°å­—ã€å¸¦K/M/Bçš„æ•°å­—
                        if re.match(r'^\d+(\.\d+)?[KMB]?$', text.strip()):
                            # æ£€æŸ¥çˆ¶å…ƒç´ æ˜¯å¦åŒ…å«clapç›¸å…³å†…å®¹
                            try:
                                parent = await span.query_selector('xpath=..')
                                if parent:
                                    parent_html = await parent.inner_html()
                                    # å¦‚æœçˆ¶å…ƒç´ åŒ…å«clapç›¸å…³å†…å®¹ï¼Œå¾ˆå¯èƒ½æ˜¯ç‚¹èµæ•°
                                    if 'clap' in parent_html.lower() or 'ğŸ‘' in parent_html:
                                        claps = text.strip()
                                        break
                            except:
                                continue
                        
                        # å¤‡ç”¨æ–¹æ¡ˆï¼šæŸ¥æ‰¾çº¯æ•°å­—ï¼ˆå¦‚æœæ²¡æœ‰æ‰¾åˆ°å¸¦Kçš„ï¼‰
                        elif not claps and re.match(r'^\d+$', text.strip()):
                            try:
                                parent = await span.query_selector('xpath=..')
                                if parent:
                                    parent_html = await parent.inner_html()
                                    if 'clap' in parent_html.lower() or 'ğŸ‘' in parent_html:
                                        # ç¡®ä¿æ•°å­—åœ¨åˆç†èŒƒå›´å†…ï¼ˆç‚¹èµæ•°é€šå¸¸ä¸ä¼šå¤ªå°ï¼‰
                                        num = int(text.strip())
                                        if num > 0 and num < 1000000:  # 0-100ä¸‡ä¹‹é—´
                                            claps = text.strip()
                                            break
                            except:
                                continue
            except:
                pass
            
            # æå–è¯„è®ºæ•°
            comments = ""
            comment_selectors = [
                '[data-testid="post-preview-responses"]',
                'button[aria-label*="response"]',
                'a[href*="responses"]',
                'span:has-text("response")'
            ]
            
            for selector in comment_selectors:
                try:
                    comment_element = await article_element.query_selector(selector)
                    if comment_element:
                        comment_text = await comment_element.inner_text()
                        # æå–æ•°å­—
                        import re
                        numbers = re.findall(r'\d+', comment_text)
                        if numbers:
                            comments = numbers[0]
                            break
                except:
                    continue
            
            # è¿‡æ»¤æ²¡æœ‰æ–‡ç« é“¾æ¥çš„è®°å½•
            if not url:
                logger.debug(f"è·³è¿‡æ²¡æœ‰æ–‡ç« é“¾æ¥çš„è®°å½•: {title}")
                return None
            
            # ç”Ÿæˆå”¯ä¸€ID
            import hashlib
            unique_id = hashlib.md5(f"{title}{author}{url}".encode()).hexdigest()
            
            # æ„å»ºæ›´ä¸°å¯Œçš„å…ƒæ•°æ®ï¼ˆç§»é™¤é˜…è¯»æ—¶é•¿ï¼‰
            metadata = {
                "title": title,
                "keyword": keyword,
                "search_type": "keyword_search",
                "author_url": author_url,
                "publish_time": publish_time,
                "publish_timestamp": publish_timestamp,
                "claps": claps,
                "comments": comments
            }
            
            return DataItem(
                id=unique_id,
                platform="medium",
                content=content[:500],  # é™åˆ¶å†…å®¹é•¿åº¦
                author=author,
                url=url,
                created_at=datetime.utcnow().isoformat(),
                metadata=metadata
            )
            
        except Exception as e:
            logger.error(f"æå–æ–‡ç« æ•°æ®æ—¶å‡ºé”™: {e}")
            return None
    
    def _convert_time_to_timestamp(self, time_str: str) -> Optional[int]:
        """å°†æ—¶é—´å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ—¶é—´æˆ³"""
        try:
            import re
            from datetime import datetime, timedelta
            import time
            
            now = datetime.utcnow()
            
            # å¤„ç†ç›¸å¯¹æ—¶é—´æ ¼å¼ (å¦‚ "5d ago", "2h ago")
            if 'ago' in time_str.lower():
                # æå–æ•°å­—å’Œå•ä½
                match = re.search(r'(\d+)\s*([dhm]|day|hour|minute|week|month|year)', time_str.lower())
                if match:
                    number = int(match.group(1))
                    unit = match.group(2)
                    
                    if unit in ['d', 'day']:
                        target_time = now - timedelta(days=number)
                    elif unit in ['h', 'hour']:
                        target_time = now - timedelta(hours=number)
                    elif unit in ['m', 'minute']:
                        target_time = now - timedelta(minutes=number)
                    elif unit in ['week']:
                        target_time = now - timedelta(weeks=number)
                    elif unit in ['month']:
                        target_time = now - timedelta(days=number * 30)  # è¿‘ä¼¼
                    elif unit in ['year']:
                        target_time = now - timedelta(days=number * 365)  # è¿‘ä¼¼
                    else:
                        return None
                    
                    return int(target_time.timestamp())
            
            # å¤„ç†æœˆä»½æ ¼å¼ (å¦‚ "Jul 4", "Dec 31, 2018")
            month_map = {
                'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6,
                'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12
            }
            
            # åŒ¹é… "Jul 4" æ ¼å¼
            match = re.search(r'(jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)\s+(\d+)', time_str.lower())
            if match:
                month_name = match.group(1)
                day = int(match.group(2))
                month = month_map[month_name]
                
                # å¦‚æœåŒ…å«å¹´ä»½
                year_match = re.search(r'\b(20\d{2})\b', time_str)
                if year_match:
                    year = int(year_match.group(1))
                else:
                    # æ²¡æœ‰å¹´ä»½ï¼Œå‡è®¾æ˜¯ä»Šå¹´æˆ–å»å¹´
                    year = now.year
                    # å¦‚æœè¿™ä¸ªæ—¥æœŸåœ¨æœªæ¥ï¼Œè¯´æ˜æ˜¯å»å¹´
                    if month > now.month or (month == now.month and day > now.day):
                        year = now.year - 1
                
                try:
                    target_time = datetime(year, month, day)
                    return int(target_time.timestamp())
                except ValueError:
                    return None
            
            # å¤„ç†æ ‡å‡†æ—¥æœŸæ ¼å¼ (å¦‚ "2023-12-25")
            match = re.search(r'(\d{4})-(\d{2})-(\d{2})', time_str)
            if match:
                year, month, day = map(int, match.groups())
                try:
                    target_time = datetime(year, month, day)
                    return int(target_time.timestamp())
                except ValueError:
                    return None
            
            # å¦‚æœæ˜¯ISOæ ¼å¼ï¼Œç›´æ¥è§£æ
            if 'T' in time_str:
                try:
                    target_time = datetime.fromisoformat(time_str.replace('Z', '+00:00'))
                    return int(target_time.timestamp())
                except ValueError:
                    return None
            
            return None
            
        except Exception as e:
            logger.debug(f"æ—¶é—´è½¬æ¢å¤±è´¥: {time_str} -> {e}")
            return None
    
    async def get_rate_limit(self) -> RateLimitInfo:
        """è·å–å½“å‰é™åˆ¶ä¿¡æ¯"""
        return self.rate_limit
    
    async def cleanup(self) -> None:
        """æ¸…ç†èµ„æº"""
        try:
            if self.page and not self.page.is_closed():
                await self.page.close()
            if self.browser:
                await self.browser.close()
            if self.playwright:
                await self.playwright.stop()
            logger.info("Medium é€‚é…å™¨èµ„æºæ¸…ç†å®Œæˆ")
        except Exception as e:
            logger.error(f"æ¸…ç† Medium é€‚é…å™¨èµ„æºå¤±è´¥: {e}")
        finally:
            self.page = None
            self.browser = None
            self.playwright = None
            self.authenticated = False